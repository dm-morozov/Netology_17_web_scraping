# Проект по парсингу вакансий и статей

Этот учебный проект предназначен для парсинга вакансий с сайта HeadHunter и статей с сайта Habr. Проект написан на языке Python и использует библиотеки BeautifulSoup, Selenium и другие. В данном проекте представлены примеры использования различных техник парсинга данных.

## Описание

### Парсинг вакансий с HeadHunter

Проект выполняет поиск вакансий по запросу "Python" в городах Москва, Санкт-Петербург и Оренбург. Вакансии фильтруются по наличию ключевых слов "Django" и "Flask" в описании, а также по валюте зарплаты (только USD). Результаты сохраняются в файл формата JSON.

### Парсинг статей с Habr

Проект собирает статьи с главной страницы раздела "Статьи" на Habr, извлекает их заголовки, ссылки и краткие описания, и сохраняет эти данные.

## Установка

1. Клонируйте репозиторий:
    
    ```
    git clone https://github.com/dm-morozov/Netology_17_web_scraping
    cd Netology_17_web_scraping
    ```
    
2. Установите зависимости:
    
    ```
    pip install -r requirements.txt
    ```
    

## Файлы

### Основные файлы

- `home_work.py`: Скрипт для парсинга вакансий с сайта HeadHunter.
- `class_work.py`: Скрипт для парсинга данных с сайта iplocation.net и Habr.
- `class_work_selenium_hubr.py`: Скрипт для парсинга статей с сайта Habr с использованием Selenium.
- `vacancies.json`: JSON-файл, содержащий информацию о собранных вакансиях.
- `requirements.txt`: Файл с зависимостями проекта.

### Описание файлов

### home_work.py

Скрипт для парсинга вакансий с сайта HeadHunter. Использует библиотеки `requests`, `BeautifulSoup`, `fake_headers` и `selenium`. Скрипт ищет вакансии с ключевыми словами "Django" и "Flask" и сохраняет их в JSON-файл.

### class_work.py

Скрипт для парсинга данных с сайта iplocation.net и статей с сайта Habr. Использует библиотеки `requests`, `BeautifulSoup` и `fake_headers`. Скрипт извлекает заголовок и IP-адрес с сайта iplocation.net, а также заголовки, ссылки и описания статей с сайта Habr.

### class_work_selenium_hubr.py

Скрипт для парсинга статей с сайта Habr с использованием Selenium. Извлекает заголовки статей, ссылки и краткие описания.

### vacancies.json

JSON-файл, содержащий информацию о собранных вакансиях: ссылка, вилка зарплаты, название компании, город и описание вакансии.

### requirements.txt

Файл содержит список зависимостей проекта, необходимых для выполнения скриптов.

## Запуск

1. Для запуска скрипта `home_work.py` выполните:
    
    ```
    python home_work.py
    ```
    
2. Для запуска скрипта `class_work.py` выполните:
    
    ```
    python class_work.py
    ```
    
3. Для запуска скрипта `class_work_selenium_hubr.py` выполните:
    
    ```
    python class_work_selenium_hubr.py
    ```
    

## Зависимости

Проект использует следующие библиотеки:

- `requests`
- `beautifulsoup4`
- `fake_headers`
- `selenium`
- и другие, указанные в `requirements.txt`.